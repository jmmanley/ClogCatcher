{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from networks import CNNFeatureLSTM\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.ClogData('/ssd_icybox2_1TB/jason/clog-loss-data/', size='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only files that have been downloaded\n",
    "\n",
    "downloaded = d.train.apply(lambda x: os.path.exists(os.path.join(d.path, x.filename[:-4] + '_cropped.mp4')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "      <th>project_id</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>crowd_score</th>\n",
       "      <th>tier1</th>\n",
       "      <th>micro</th>\n",
       "      <th>nano</th>\n",
       "      <th>stalled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>F</td>\n",
       "      <td>48</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>H</td>\n",
       "      <td>122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>E</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>C</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570501</th>\n",
       "      <td>684600.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>A</td>\n",
       "      <td>49</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570636</th>\n",
       "      <td>684744.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>G</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571469</th>\n",
       "      <td>685597.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>K</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571511</th>\n",
       "      <td>685640.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>C</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572147</th>\n",
       "      <td>686290.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>A</td>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322837 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                                url  \\\n",
       "0       100000.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "1       100001.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "2       100002.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "3       100003.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "4       100004.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "...            ...                                                ...   \n",
       "570501  684600.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "570636  684744.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "571469  685597.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "571511  685640.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "572147  686290.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "\n",
       "       project_id  num_frames  crowd_score  tier1  micro   nano  stalled  \n",
       "0               M          54     0.000000   True  False  False        0  \n",
       "1               F          48     0.022769  False  False  False        0  \n",
       "2               H         122     0.000000   True  False  False        0  \n",
       "3               E          55     0.000000   True  False  False        0  \n",
       "4               C          56     0.000000   True  False  False        0  \n",
       "...           ...         ...          ...    ...    ...    ...      ...  \n",
       "570501          A          49     1.000000   True   True   True        1  \n",
       "570636          G          53     0.000000   True   True   True        0  \n",
       "571469          K          48     0.000000   True   True   True        0  \n",
       "571511          C          58     0.000000   True   True  False        0  \n",
       "572147          A          65     0.000000   True   True  False        0  \n",
       "\n",
       "[322837 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.train = d.train[downloaded]\n",
    "\n",
    "d.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = len(d.train)/d.train.stalled.value_counts().values/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_frames(x):\n",
    "    import cv2\n",
    "    \n",
    "    if os.path.exists(x):\n",
    "    \n",
    "        cap = cv2.VideoCapture(x)\n",
    "\n",
    "        return int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = d.train.apply(lambda x: get_n_frames(os.path.join(d.path, x.filename[:-4] + '_cropped.mp4')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.applications.VGG16()\n",
    "latent_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "LOADING CNN FEATURES...\n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_matthewcorr` which is not available. Available metrics are: loss,accuracy,matthewcorr\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1000, 512, 1, 100, 32, 512] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[StatefulPartitionedCall]] [Op:__inference_distributed_function_1773773]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f592b503bb25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                                \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                                \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                                                restore_best_weights=True)], verbose=0)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_matthewcorr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/clog-loss/networks.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, clogData, epochs, validate, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TRAINING CLASSIFICATION MODEL...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/ssd_icybox2_1TB/jason/miniconda3/envs/clog/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1000, 512, 1, 100, 32, 512] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[StatefulPartitionedCall]] [Op:__inference_distributed_function_1773773]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "# DO SOME QUICK \"CROSS VALIDATION\" FOR NEURAL NET HYPERPARAMETERS\n",
    "\n",
    "lstm_units  = [64, 128, 256, 512, 1024]\n",
    "dense_units = [4, 16, 64, 128, 256, 512, 1024]\n",
    "repeats = 4\n",
    "\n",
    "mcc = np.zeros((len(lstm_units), len(dense_units), repeats))\n",
    "acc = np.zeros((len(lstm_units), len(dense_units), repeats))\n",
    "history = np.empty((len(lstm_units), len(dense_units), repeats), dtype=object)\n",
    "\n",
    "for i in range(len(lstm_units)):\n",
    "    for j in range(len(dense_units)):\n",
    "        for k in range(repeats):\n",
    "            model = CNNFeatureLSTM(cnn, cnn_dim=latent_dim, lstm_units=lstm_units[i], dense_units=dense_units[j])\n",
    "\n",
    "            history[i,j,k] = model.fit(d, epochs=50, callbacks=[EarlyStopping(monitor='val_matthewcorr', \n",
    "                                                               patience=5,\n",
    "                                                               mode='max',\n",
    "                                                               restore_best_weights=True)], verbose=0)\n",
    "\n",
    "            best_epoch = np.argmax(history[i,j,k].history['val_matthewcorr'])\n",
    "\n",
    "            mcc[i,j,k] = history[i,j,k].history['val_matthewcorr'][best_epoch]\n",
    "            acc[i,j,k] = history[i,j,k].history['val_accuracy'][best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNFeatureLSTM(cnn, cnn_dim=latent_dim, lstm_units=512, dense_units=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINDING CNN FEATURES...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 322837/322837 [47:05:59<00:00,  1.90it/s]   \n",
      "\n",
      "TRAINING CLASSIFICATION MODEL...\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(d, epochs=50, callbacks=[EarlyStopping(monitor='val_matthewcorr', \n",
    "                                                               patience=8,\n",
    "                                                               mode='max',\n",
    "                                                               restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save_weights(os.path.join(d.path, 'vgg16_lstm_512lstm_256dense_val03465.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 5532/14160 [1:01:11<1:43:35,  1.39it/s]"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(d, train=False).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'filename':d.test.filename.values, 'stalled': (predictions.flatten() > 0.5).astype(int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(d.path, 'pred_vgg16_lstm_512lstm_256dense_val03465.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi'); x=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clog] *",
   "language": "python",
   "name": "conda-env-clog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
